{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ham or Spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to classify emails as spams (1) or normal emails (0)\n",
    "\n",
    "üßπ First, you will apply cleaning techniques to these textual data\n",
    "\n",
    "üë©üèª‚Äçüî¨ Then, you will convert the cleaned texts into a numerical represensation\n",
    "\n",
    "‚úâÔ∏è Eventually, you will apply the ***Multinomial Naive Bayes*** model to classify each email as either a spam or a regular email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) The NTLK library (Natural Language Toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/bitazaratustra/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages (3.6.7)\n",
      "Requirement already satisfied: joblib in /home/bitazaratustra/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/bitazaratustra/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /home/bitazaratustra/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/bitazaratustra/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages (from nltk) (2021.11.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/bitazaratustra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bitazaratustra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/bitazaratustra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/bitazaratustra/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#When importing nltk for the first time, we need to also download a few built-in libraries\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"emails.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Cleaning the (text) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is made up of emails that are classified as ham [0] or spam[1]. You need to clean the dataset before training a prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to remove the punctuation. Apply it to the `text` column and add the output to a new column in the dataframe called `clean_text` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Subject naturally irresistible your corporate ...\n",
       "1       Subject the stock trading gunslinger  fanny is...\n",
       "2       Subject unbelievable new homes made easy  im w...\n",
       "3       Subject 4 color printing special  request addi...\n",
       "4       Subject do not have money  get software cds fr...\n",
       "                              ...                        \n",
       "5723    Subject re  research and development charges t...\n",
       "5724    Subject re  receipts from visit  jim   thanks ...\n",
       "5725    Subject re  enron case study update  wow  all ...\n",
       "5726    Subject re  interest  david   please  call shi...\n",
       "5727    Subject news  aurora 5  2 update  aurora versi...\n",
       "Name: clean_text, Length: 5728, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import string\n",
    "\n",
    "df['clean_text'] = df.text\n",
    "\n",
    "string.punctuation\n",
    "for punctuation in string.punctuation:\n",
    "    df['clean_text'] = df['clean_text'].map(lambda x : x.replace(punctuation, ''))\n",
    "    \n",
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Lower Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to lowercase the text. Apply it to `clean_text` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def basic_cleaning(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') \n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject 4 color printing special  request addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject news  aurora 5  2 update  aurora versi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     Subject naturally irresistible your corporate ...  \n",
       "1     Subject the stock trading gunslinger  fanny is...  \n",
       "2     Subject unbelievable new homes made easy  im w...  \n",
       "3     Subject 4 color printing special  request addi...  \n",
       "4     Subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  Subject re  research and development charges t...  \n",
       "5724  Subject re  receipts from visit  jim   thanks ...  \n",
       "5725  Subject re  enron case study update  wow  all ...  \n",
       "5726  Subject re  interest  david   please  call shi...  \n",
       "5727  Subject news  aurora 5  2 update  aurora versi...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     subject naturally irresistible your corporate ...  \n",
       "1     subject the stock trading gunslinger  fanny is...  \n",
       "2     subject unbelievable new homes made easy  im w...  \n",
       "3     subject  color printing special  request addit...  \n",
       "4     subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  subject re  research and development charges t...  \n",
       "5724  subject re  receipts from visit  jim   thanks ...  \n",
       "5725  subject re  enron case study update  wow  all ...  \n",
       "5726  subject re  interest  david   please  call shi...  \n",
       "5727  subject news  aurora    update  aurora version...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "df['clean_text'] = df['clean_text'].map(basic_cleaning)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Remove Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to remove numbers from the text. Apply it to `clean_text` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "df['clean_text'] = df['clean_text'].map(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, naturally, irresistible, your, corpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, the, stock, trading, gunslinger, fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, unbelievable, new, homes, made, easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, color, printing, special, request, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, do, not, have, money, get, software,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, re, research, and, development, char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, re, receipts, from, visit, jim, than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, re, enron, case, study, update, wow,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, re, interest, david, please, call, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, news, aurora, update, aurora, versio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [subject, naturally, irresistible, your, corpo...  \n",
       "1     [subject, the, stock, trading, gunslinger, fan...  \n",
       "2     [subject, unbelievable, new, homes, made, easy...  \n",
       "3     [subject, color, printing, special, request, a...  \n",
       "4     [subject, do, not, have, money, get, software,...  \n",
       "...                                                 ...  \n",
       "5723  [subject, re, research, and, development, char...  \n",
       "5724  [subject, re, receipts, from, visit, jim, than...  \n",
       "5725  [subject, re, enron, case, study, update, wow,...  \n",
       "5726  [subject, re, interest, david, please, call, s...  \n",
       "5727  [subject, news, aurora, update, aurora, versio...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to remove stopwords from the text. Apply it to `clean_text`. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "    \n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    \n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize \n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "    \n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "        \n",
    "    ]\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"s\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "        \n",
    "    ]\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"a\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "        \n",
    "    ]\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "        \n",
    "    ]\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"r\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "        \n",
    "    ]\n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "    \n",
    "    return cleaned_sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy im wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject color printing special request additio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject money get software cds software compat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject research development charges gpg forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject receipts visit jim thanks invitation v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject enron case study update wow day super ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject interest david please call shirley cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject news aurora update aurora version fast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     subject naturally irresistible corporate ident...  \n",
       "1     subject stock trading gunslinger fanny merrill...  \n",
       "2     subject unbelievable new homes made easy im wa...  \n",
       "3     subject color printing special request additio...  \n",
       "4     subject money get software cds software compat...  \n",
       "...                                                 ...  \n",
       "5723  subject research development charges gpg forwa...  \n",
       "5724  subject receipts visit jim thanks invitation v...  \n",
       "5725  subject enron case study update wow day super ...  \n",
       "5726  subject interest david please call shirley cre...  \n",
       "5727  subject news aurora update aurora version fast...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df.text.apply(cleaning)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.5) Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to lemmatize the text. Make sure the output is a single string, not a list of words. Apply it to `clean_text`. ‚ùì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Bag-of-words Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Digitizing the textual data into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Vectorize the `clean_text` to a Bag-of-Words representation with a default CountVectorizer. Save as `X_bow`. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_bow = count_vectorizer.fit_transform(df['clean_text'])\n",
    "X_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1327/466521257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m X_bow = pd.DataFrame(X_bow.toarray(), \n\u001b[0m\u001b[1;32m      4\u001b[0m                                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 index = df.clean_text)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_bow = pd.DataFrame(X_bow.toarray(), \n",
    "                                columns = count_vectorizer.get_feature_names_out(),\n",
    "                                index = df.clean_text)\n",
    "\n",
    "X_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 33566)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Multinomial Naive Bayes Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Cross-validate a MultinomialNB model with the bag-of-words data. Score the model's accuracy. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 168)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Feature/Target\n",
    "X = df[\"clean_text\"]\n",
    "y = df[\"spam\"]\n",
    "\n",
    "# Pipeline vectorizer + Naive Bayes\n",
    "pipeline_naive_bayes = make_pipeline(TfidfVectorizer(), \n",
    "                                     MultinomialNB())\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(pipeline_naive_bayes, X, y, cv = 5, scoring = [\"accuracy\"])\n",
    "average_accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "np.round(average_accuracy,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations !\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
