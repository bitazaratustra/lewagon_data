{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üè† Import the house price data set. We will keep only numerical features for the sake of simplicity\n",
    "\n",
    "üéØ Your goal will be to fit the best KNN Regressor. In particular, how many \"neighbors\" (<font color=blue>K</font> in <font color=blue>K</font>NN) should you consider to get the best predictions for your house prices ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>...</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0        1          60         65.0     8450            7            5   \n",
       "1        2          20         80.0     9600            6            8   \n",
       "2        3          60         68.0    11250            7            5   \n",
       "3        4          70         60.0     9550            7            5   \n",
       "4        5          60         84.0    14260            8            5   \n",
       "...    ...         ...          ...      ...          ...          ...   \n",
       "1455  1456          60         62.0     7917            6            5   \n",
       "1456  1457          20         85.0    13175            6            6   \n",
       "1457  1458          70         66.0     9042            7            9   \n",
       "1458  1459          20         68.0     9717            5            6   \n",
       "1459  1460          20         75.0     9937            5            6   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  \\\n",
       "0          2003          2003       196.0         706  ...           0   \n",
       "1          1976          1976         0.0         978  ...         298   \n",
       "2          2001          2002       162.0         486  ...           0   \n",
       "3          1915          1970         0.0         216  ...           0   \n",
       "4          2000          2000       350.0         655  ...         192   \n",
       "...         ...           ...         ...         ...  ...         ...   \n",
       "1455       1999          2000         0.0           0  ...           0   \n",
       "1456       1978          1988       119.0         790  ...         349   \n",
       "1457       1941          2006         0.0         275  ...           0   \n",
       "1458       1950          1996         0.0          49  ...         366   \n",
       "1459       1965          1965         0.0         830  ...         736   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0              61              0          0            0         0        0   \n",
       "1               0              0          0            0         0        0   \n",
       "2              42              0          0            0         0        0   \n",
       "3              35            272          0            0         0        0   \n",
       "4              84              0          0            0         0        0   \n",
       "...           ...            ...        ...          ...       ...      ...   \n",
       "1455           40              0          0            0         0        0   \n",
       "1456            0              0          0            0         0        0   \n",
       "1457           60              0          0            0         0     2500   \n",
       "1458            0            112          0            0         0        0   \n",
       "1459           68              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "0          2    2008     208500  \n",
       "1          5    2007     181500  \n",
       "2          9    2008     223500  \n",
       "3          2    2006     140000  \n",
       "4         12    2008     250000  \n",
       "...      ...     ...        ...  \n",
       "1455       8    2007     175000  \n",
       "1456       2    2010     210000  \n",
       "1457       5    2010     266500  \n",
       "1458       4    2010     142125  \n",
       "1459       6    2008     147500  \n",
       "\n",
       "[1121 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data\n",
    "data = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv')\n",
    "\n",
    "# Only keep numerical columns and raws without NaN\n",
    "data = data.select_dtypes(include=np.number).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Holdout)**‚ùì\n",
    "\n",
    "üëá Split the dataset to create your `X_train` `X_test` and `y_train` `y_test`. Use:\n",
    "- `test_size=0.3`\n",
    "- `random_state=0` to compare your results with your buddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öñÔ∏è Scaling is always crucially important for the KNN algorithm..\n",
    "\n",
    "‚ùì **Question (Scaling)** ‚ùì \n",
    "\n",
    "* Scale your train set and test set.\n",
    "* Here, let's simply apply the `StandardScaler` and not waste time choosing one scaler per feature. Indeed, the goals of this exercise are to:\n",
    "    * review KNN\n",
    "    * understand GridSearchCV\n",
    "    * understand RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train, X_test)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (A baseline for our KNN)** ‚ùì\n",
    "\n",
    "Cross-validate (*cv = 5*) a simple KNN regressor taking into account only _the closest neighbor_, and compute the average score over the 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.569025195507008"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "cv = cross_validate(model,X_train_scaled, Y_train, cv=5)\n",
    "\n",
    "cv['test_score'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. A first GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch v1)**‚ùì\n",
    "\n",
    "Let's use SKLearn `GridSearchCV` to find the best KNN hyperparameter `n_neighbors`.\n",
    "- Start a coarse-grain approach, with `n_neighbors` = [1,5,10,20,50]\n",
    "- 5-fold cross-validate each parameter\n",
    "- Make sure to maximize your performance time using `n_jobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instantiate model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors' : [1,5,10,20,50]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "search = GridSearchCV(model, grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train_scaled, Y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters)** ‚ùì\n",
    "\n",
    "According to the GridSearch, what is the optimal K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 20}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (scoring)** ‚ùì What is the best score the optimal K value produced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594265833471792"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. A second GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch V2)** ‚ùì\n",
    "\n",
    "\n",
    "Now, we have an idea about where the best $K$ lies, but some of the values we didn't try could result in a  better performance.\n",
    "\n",
    "* Re-run a GridSearch trying some values for $K$ around to your previous best value\n",
    "* What are the `best_score` and `best_k` for this refined GridSearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors': [15,17,20,23,25]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "search2 = GridSearchCV(model, grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "search2.fit(X_train_scaled, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = search2.best_score_\n",
    "best_k = search2.best_params_['n_neighbors']\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/bitazaratustra/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/bitazaratustra/code/bitazaratustra/data-challenges/05-ML/05-Model-Tuning/01-Workflow\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "tests/test_knn.py::TestKnn::test_best_k \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 50%]\u001b[0m\n",
      "tests/test_knn.py::TestKnn::test_best_score \u001b[32mPASSED\u001b[0m\u001b[32m                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.14s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/knn.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed knn step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('knn',\n",
    "                         best_k=best_k,\n",
    "                         best_score=best_score)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Visual check (manual GridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This problem is actually simple enough to perform a GridSearch manually.\n",
    "\n",
    "‚ùì **Question(Manual GridSearch)** ‚ùì\n",
    "\n",
    "- Loop manually over all values of $K$ from $1$ to $50$ and store the average of the cross-validated scores of each model in a list.\n",
    "- Plot the scores as a function of $K$ to visually find the best $K$ using the `Elbow Method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "model = KNeighborsRegressor()\n",
    "lista = []\n",
    "\n",
    "for i in np.arange(1,51):\n",
    "    grid = {'n_neighbors': [i]}\n",
    "    search_50 = GridSearchCV(model, grid, cv=5, n_jobs=-1)\n",
    "    lista.append(search_50.fit(X_train_scaled, Y_train).best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x = np.arange(1,51),y=lista);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìCan you guess what makes GridSearchCV a better option than such manual loop ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "- Sklearn's `n_jobs=-1` allows you to paralellize the search, utilizing all of your CPU cores\n",
    "- What if you had multiple hyper-parameters to co-optimize?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GridSearch with multiple parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ KNNRegressor suppports various _distance metrics_ via the hyper-parameter `p` \n",
    "\n",
    "üìö [sklearn.neighbors.KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "\n",
    "‚ùì **Question (tuning multiple parameters)** ‚ùì\n",
    "\n",
    "\n",
    "* Use GridSearchCV to search for the best $K$ and $p$ simultaneously.\n",
    "    * Try all combinations for $K = [1, 5, 10, 20, 50]$ and $p = [1, 2, 3]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 10, 'p': 1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "grid = {'n_neighbors': [1,5,10,20,50] , 'p':[1,2,3]}\n",
    "\n",
    "search_x_2 = GridSearchCV(model, grid, cv=5, n_jobs=-1)\n",
    "\n",
    "search_x_2.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (number of submodels)**‚ùì\n",
    "\n",
    "How many submodels did you train overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "Much more than 15. Think twice :)\n",
    "    <details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "75 models due to CV=5\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters and best score after tuning the model with multiple parameters)**‚ùì\n",
    "\n",
    "What are the *best parameters* and the *best score*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 10, 'p': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "search_x_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978142226309175"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_x_2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see whether a RandomizedSearch can find a better combination with the same number of models being fitted.\n",
    "\n",
    "‚ùì **Question (RandomizedSearchCV)** ‚ùì\n",
    "\n",
    "Use `RandomizedSearchCV` to\n",
    "- Randomly sample $K$ from a uniform `randint(1,50)` distribition\n",
    "- Sample $p$ from a list $[1,2,3]$\n",
    "- Use the correct numbers of `n_iter` and `cv` to fit the exact same numbers of models as in your previous GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(), n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f553d289d60>,\n",
       "                                        'p': [1, 2, 3]})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "grid = {'n_neighbors': stats.randint(1,50), 'p': [1,2,3]}\n",
    "search_random = RandomizedSearchCV(model, grid, n_iter=15, cv=5, n_jobs=-1)\n",
    "\n",
    "search_random.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014890013854652"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (finetuning your model one more time)**‚ùì\n",
    "\n",
    "- Refine your RandomsearchCV if you want\n",
    "- Choose your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "data = [search.best_score_,search2.best_score_,search_50.best_score_, search_x_2.best_score_, search_random.best_score_]\n",
    "modelos = ['model1', 'model2', 'model3', 'model4', 'model5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to display your `cv_results` as a `DataFrame`, this will help you visualize what's going on inside the CV! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0.759427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0.763679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0.724501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>0.797814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model5</th>\n",
       "      <td>0.801489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "model1  0.759427\n",
       "model2  0.763679\n",
       "model3  0.724501\n",
       "model4  0.797814\n",
       "model5  0.801489"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE \n",
    "cv_results = pd.DataFrame(data, index=modelos, columns=['score'])\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Evaluation of the \"best\" model)** ‚ùì\n",
    "\n",
    "* Time has come to discover our model's performance with \"best params\" on the **unseen** test set `X_test`.\n",
    "    * Compute the r2 score for the test set and save it as `r2_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "search_random.fit(X_test_scaled, Y_test)\n",
    "\n",
    "r2_test = search_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Taking a step back)** ‚ùì\n",
    "\n",
    "Would you consider the optimized model to generalize well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer</summary>\n",
    "\n",
    "Test score may decrease a bit with train set. Probably not more than 5%. This can be due to\n",
    "- A non-representative train/test split\n",
    "- A cross-val number too small leading to overfitting the model-tuning phase. The more you cross-validated, the more robust your findings will generalize - but you can't increase cv too much if your dataset is too small as you won't keep enough observations in each fold to be representative.\n",
    "- Our dataset is very small and our hyperparameter optimization is thus extremely dependent (and overfitting) on our train/test split. Always make sure your dataset is much bigger than the total number of hyperparameter combinations you are trying out!\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.12, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- /home/bitazaratustra/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/bitazaratustra/code/bitazaratustra/data-challenges/05-ML/05-Model-Tuning/01-Workflow\n",
      "plugins: anyio-3.4.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_r2.py::TestR2::test_r2 \u001b[32mPASSED\u001b[0m\u001b[32m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.15s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/r2.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed r2 step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('r2', \n",
    "                         r2_test=r2_test)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to finetune a model using either a GridSearchCV or a RandomizedSearchCV \n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
