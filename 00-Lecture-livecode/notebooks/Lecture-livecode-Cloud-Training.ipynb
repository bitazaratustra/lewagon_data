{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The livecodes of the lecture are based on the code used by the students during the challenges.\n",
    "\n",
    "We will use the **cloud lecture** challenge for all the livecodes of the lecture.\n",
    "\n",
    "Myriad batches:\n",
    "\n",
    "``` bash\n",
    "cd mlops-cloud-lecture\n",
    "```\n",
    "\n",
    "Legacy batches:\n",
    "\n",
    "``` bash\n",
    "cd data-challenges/07-ML-Ops/02-Cloud-training/00-Lecture-livecode\n",
    "```\n",
    "\n",
    "Download data:\n",
    "\n",
    "``` bash\n",
    "curl https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/train_10k.csv > ~/.lewagon/mlops/data/raw/train_10k.csv\n",
    "curl https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/val_10k.csv > ~/.lewagon/mlops/data/raw/val_10k.csv\n",
    "```\n",
    "\n",
    "Then use VSCode:\n",
    "\n",
    "``` bash\n",
    "code .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the model trains:\n",
    "\n",
    "``` bash\n",
    "make run_preprocess run_train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equivalent to running **interface/main.py** with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# preprocess_and_train()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mpreprocess\u001b[49m()\n\u001b[1;32m      4\u001b[0m     train()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # preprocess_and_train()\n",
    "    preprocess()\n",
    "    train()\n",
    "    # pred()\n",
    "    # evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_target/local_model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_local_model(model, suffix):\n",
    "\n",
    "    if model:\n",
    "\n",
    "        model_path = os.path.join(os.environ.get(\"LOCAL_REGISTRY_PATH\"), \"models\",\n",
    "                                  suffix + \".pickle\")\n",
    "\n",
    "        print(f\"- model path: {model_path}\")\n",
    "\n",
    "        model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_target/cloud_model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cloud_model(model, suffix):\n",
    "\n",
    "    print(\"TODO: save model in the cloud ðŸ§¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data_sources/cloud_data.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cloud_chunk(path,\n",
    "                    index,\n",
    "                    chunk_size,\n",
    "                    dtypes,\n",
    "                    columns):\n",
    "\n",
    "    print(\"TODO: get cloud chunk ðŸ§©\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ml_logic/registry.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'taxifare.model_target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtaxifare\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_target\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocal_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_local_model\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtaxifare\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_target\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_cloud_model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL_TARGET\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'taxifare.model_target'"
     ]
    }
   ],
   "source": [
    "from taxifare.model_target.local_model import save_local_model\n",
    "from taxifare.model_target.cloud_model import save_cloud_model\n",
    "\n",
    "if os.environ[\"MODEL_TARGET\"] == \"local\":\n",
    "            save_local_model(model, suffix)\n",
    "elif os.environ[\"MODEL_TARGET\"] == \"cloud\":\n",
    "            save_cloud_model(model, suffix)\n",
    "else:\n",
    "    raise ValueError(f\"Invalid .env config for model: {os.environ['MODEL_TARGET']} ðŸ¤•\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ml_logic/data.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxifare.data_sources.cloud_data import get_cloud_chunk\n",
    "\n",
    "    if os.environ[\"DATA_SOURCE\"] == \"local\":\n",
    "        chunk_df = get_pandas_chunk(path=source_name,\n",
    "                                    index=index,\n",
    "                                    chunk_size=chunk_size,\n",
    "                                    dtypes=dtypes,\n",
    "                                    columns=columns)\n",
    "    elif os.environ[\"DATA_SOURCE\"] == \"cloud\":\n",
    "        chunk_df = get_cloud_chunk(table=source_name,\n",
    "                                   index=index,\n",
    "                                   chunk_size=chunk_size,\n",
    "                                   dtypes=dtypes)\n",
    "    else:\n",
    "        raise NameError(f\"Invalid .env conf for data: {os.environ['DATA_SOURCE']} ðŸ˜¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "BUCKET_NAME = \"my-bucket\"\n",
    "\n",
    "storage_filename = \"models/random_forest_model.joblib\"\n",
    "local_filename = \"model.joblib\"\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(storage_filename)\n",
    "blob.upload_from_filename(local_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_target/cloud_model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def save_cloud_model(model, suffix):\n",
    "\n",
    "    # save the model\n",
    "    if model:\n",
    "\n",
    "        model_path = os.path.join(os.environ.get(\"LOCAL_REGISTRY_PATH\"), \"models\",\n",
    "                                  suffix + \".pickle\")\n",
    "\n",
    "        model.save(model_path)\n",
    "\n",
    "        # list model files\n",
    "        files = glob.glob(f\"{model_path}/**/*.*\", recursive=True)\n",
    "\n",
    "        for file in files:\n",
    "            storage_filename = file[17:]\n",
    "\n",
    "            client = storage.Client()\n",
    "            bucket = client.bucket(os.environ[\"BUCKET_NAME\"])\n",
    "            blob = bucket.blob(storage_filename)\n",
    "            blob.upload_from_filename(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "rows = client.list_rows(table, start_index=index, max_results=chunk_size)\n",
    "big_query_df = rows.to_dataframe()\n",
    "\n",
    "if big_query_df.shape[0] == 0:\n",
    "    return None  # end of data\n",
    "\n",
    "big_query_df = big_query_df.astype(dtypes)\n",
    "\n",
    "return big_query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data_sources/cloud_data.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def get_cloud_chunk(table, index, chunk_size, dtypes):\n",
    "\n",
    "    table = f\"{os.environ['PROJECT']}.{os.environ['DATASET']}.{table}\"\n",
    "\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    rows = client.list_rows(table, start_index=index, max_results=chunk_size)\n",
    "\n",
    "    big_query_df = rows.to_dataframe()\n",
    "\n",
    "    if big_query_df.shape[0] == 0:\n",
    "        return None  # end of data\n",
    "\n",
    "    big_query_df = big_query_df.astype(dtypes)\n",
    "\n",
    "    print(f\"Data loaded from BQ ðŸ”¥\")\n",
    "    print(big_query_df.head())\n",
    "\n",
    "    return big_query_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a VM by following the **training in the cloud** challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "BUCKET_NAME = \"my-bucket\"\n",
    "\n",
    "storage_filename = \"models/random_forest_model.joblib\"\n",
    "local_filename = \"model.joblib\"\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(storage_filename)\n",
    "blob.upload_from_filename(local_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "rows = client.list_rows(table, start_index=index, max_results=chunk_size)\n",
    "big_query_df = rows.to_dataframe()\n",
    "\n",
    "if big_query_df.shape[0] == 0:\n",
    "    return None  # end of data\n",
    "\n",
    "big_query_df = big_query_df.astype(dtypes)\n",
    "\n",
    "return big_query_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "73fd760d7b33bae014415344f13633036d7de627f97c22402e871d8c4e5a81a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
